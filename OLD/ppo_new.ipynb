{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yfinance as yf\n",
    "from vnstock import Vnstock\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "from gymnasium import spaces\n",
    "import gymnasium as gym\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import talib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "from datetime import datetime\n",
    "\n",
    "from stable_baselines3 import SAC, PPO, A2C, TD3\n",
    "from sb3_contrib import RecurrentPPO, TRPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(vn_stock_list, global_stock_list, starting, ending) -> pd.DataFrame:\n",
    "    # Create a full date range including weekends\n",
    "    date_range = pd.date_range(start=starting, end=ending, freq='D')\n",
    "    stock_data_dict = {}\n",
    "    \n",
    "    print(f\"Fetching {len(vn_stock_list)} Vietnamese stock data...\")\n",
    "    for stock in vn_stock_list:\n",
    "        try:\n",
    "            data = Vnstock().stock(symbol=stock, source='VCI').quote.history(\n",
    "                start=starting, end=ending\n",
    "            )\n",
    "            # Reset index and rename 'time' to 'date'\n",
    "            data.reset_index(inplace=True)\n",
    "            data.rename(columns={'time': 'date'}, inplace=True)\n",
    "            # Convert 'date' to datetime and set as index\n",
    "            data['date'] = pd.to_datetime(data['date'])\n",
    "            data.set_index('date', inplace=True)\n",
    "            # Select relevant columns\n",
    "            data = data[['open', 'high', 'low', 'close']]\n",
    "            \n",
    "            # Create a new DataFrame with all dates, but keep NaN values for now\n",
    "            full_data = pd.DataFrame(index=date_range, columns=data.columns)\n",
    "            full_data.loc[data.index] = data  # Add existing data\n",
    "            \n",
    "            # Fill gap days with evenly distributed price changes\n",
    "            full_data = fill_price_gaps_evenly(full_data)\n",
    "            \n",
    "            # Create multi-index with stock symbol and metrics\n",
    "            full_data.columns = pd.MultiIndex.from_product([[stock], full_data.columns], names=['Stock', 'Metric'])\n",
    "            stock_data_dict[stock] = full_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {stock}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Fetching {len(global_stock_list)} Global stock data...\")\n",
    "    for stock in global_stock_list:\n",
    "        try:\n",
    "            data = yf.download(stock, start=starting, end=ending)\n",
    "            # Ensure index is datetime\n",
    "            data.index = pd.to_datetime(data.index)\n",
    "            \n",
    "            # Select and rename columns to match Vietnamese stock format\n",
    "            data = data[['Open', 'High', 'Low', 'Close']]\n",
    "            data.columns = ['open', 'high', 'low', 'close']\n",
    "            \n",
    "            price_columns = ['open', 'high', 'low', 'close']\n",
    "            data[price_columns] = data[price_columns] * 25.5  # Multiply by 25.5 for USD to VND conversion\n",
    "            \n",
    "            # Limit to 2 decimal places\n",
    "            data[price_columns] = data[price_columns].round(2)\n",
    "            \n",
    "            # Create a new DataFrame with all dates, but keep NaN values for now\n",
    "            full_data = pd.DataFrame(index=date_range, columns=data.columns)\n",
    "            full_data.loc[data.index] = data  # Add existing data\n",
    "            \n",
    "            # Fill gap days with evenly distributed price changes\n",
    "            full_data = fill_price_gaps_evenly(full_data)\n",
    "            \n",
    "            # Create multi-index with stock symbol and metrics\n",
    "            full_data.columns = pd.MultiIndex.from_product([[stock], full_data.columns], names=['Stock', 'Metric'])\n",
    "            stock_data_dict[stock] = full_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {stock}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Concatenate all stock data horizontally\n",
    "    if stock_data_dict:\n",
    "        combined_data = pd.concat(stock_data_dict.values(), axis=1)\n",
    "        \n",
    "        # Set title for all columns\n",
    "        combined_data.columns = pd.MultiIndex.from_tuples(combined_data.columns, names=['Stock', 'Metric'])\n",
    "        \n",
    "        # Sort columns by stock name\n",
    "        combined_data = combined_data.sort_index(axis=1, level='Stock')\n",
    "        \n",
    "        # Check for any remaining NaN values\n",
    "        null_counts = combined_data.isnull().sum()\n",
    "        if null_counts.sum() > 0:\n",
    "            print(\"Warning: There are still NaN values in the data:\")\n",
    "            print(null_counts[null_counts > 0])\n",
    "        \n",
    "        return combined_data\n",
    "    else:\n",
    "        raise ValueError(\"No stock data was successfully fetched.\")\n",
    "\n",
    "\n",
    "def fill_price_gaps_evenly(df):\n",
    "    \"\"\"\n",
    "    Fill gaps in price data by evenly distributing the price change across missing days.\n",
    "    \n",
    "    For each gap:\n",
    "    1. Find the last value before the gap and the first value after the gap\n",
    "    2. Calculate the total change for each metric (open, high, low, close)\n",
    "    3. Distribute this change evenly across the missing days\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Loop through each column (open, high, low, close)\n",
    "    for col_name in result.columns:\n",
    "        # Find sequences of NaN values\n",
    "        is_nan = result[col_name].isna()\n",
    "        \n",
    "        if not is_nan.any():\n",
    "            continue  # Skip if no NaN values in this column\n",
    "        \n",
    "        # Find the start and end indices of each gap\n",
    "        gap_starts = []\n",
    "        gap_ends = []\n",
    "        \n",
    "        in_gap = False\n",
    "        for i in range(len(is_nan)):\n",
    "            if is_nan.iloc[i] and not in_gap:\n",
    "                gap_starts.append(i)\n",
    "                in_gap = True\n",
    "            elif not is_nan.iloc[i] and in_gap:\n",
    "                gap_ends.append(i)\n",
    "                in_gap = False\n",
    "        \n",
    "        # Handle the case where the gap extends to the end of the dataframe\n",
    "        if len(gap_starts) > len(gap_ends):\n",
    "            gap_ends.append(len(is_nan))\n",
    "        \n",
    "        # Process each gap\n",
    "        for start_idx, end_idx in zip(gap_starts, gap_ends):\n",
    "            # Skip gaps at the beginning or end where we can't calculate a gradient\n",
    "            if start_idx == 0 or end_idx == len(result):\n",
    "                continue\n",
    "            \n",
    "            # Get values before and after the gap\n",
    "            start_date = result.index[start_idx - 1]\n",
    "            end_date = result.index[end_idx]\n",
    "            \n",
    "            start_value = result.loc[start_date, col_name]\n",
    "            end_value = result.loc[end_date, col_name]\n",
    "            \n",
    "            # Calculate the total price change and the change per day\n",
    "            total_change = end_value - start_value\n",
    "            gap_length = end_idx - start_idx\n",
    "            change_per_day = total_change / (gap_length + 1)  # Include the end point in calculation\n",
    "            \n",
    "            # Fill gap days with evenly distributed price changes\n",
    "            for i in range(gap_length):\n",
    "                gap_date = result.index[start_idx + i]\n",
    "                gap_value = start_value + change_per_day * (i + 1)\n",
    "                result.loc[gap_date, col_name] = round(gap_value, 2)\n",
    "    \n",
    "    # Handle any remaining NaN values at the beginning or end\n",
    "    result = result.ffill().bfill()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoggingCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0, log_interval=500, save_path=\"plots\", filename=\"training_rewards.pdf\"):\n",
    "        super(CustomLoggingCallback, self).__init__(verbose)\n",
    "        self.rewards = []\n",
    "        self.steps = []\n",
    "        self.log_interval = log_interval\n",
    "        self.save_path = save_path\n",
    "        self.filename = filename\n",
    "\n",
    "        # Ensure the save directory exists\n",
    "        os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        reward = self.locals['rewards'][0]\n",
    "        step = self.num_timesteps\n",
    "\n",
    "        self.rewards.append(reward)\n",
    "        self.steps.append(step)\n",
    "\n",
    "        if self.verbose > 0 and step % self.log_interval == 0:\n",
    "            avg_reward = np.mean(self.rewards[-self.log_interval:])\n",
    "            max_reward = np.max(self.rewards[-self.log_interval:])\n",
    "            min_reward = np.min(self.rewards[-self.log_interval:])\n",
    "            print(f\"Step: {step}, Avg Reward: {avg_reward}, Max Reward: {max_reward}, Min Reward: {min_reward}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _on_training_end(self) -> None:\n",
    "        if self.verbose > 0:\n",
    "            total_rewards = sum(self.rewards)\n",
    "            print(f\"Training finished. Total rewards: {total_rewards}\")\n",
    "            print(f\"Total steps: {self.steps[-1]}\")\n",
    "            self.plot_training(self.rewards)\n",
    "\n",
    "    def plot_training(self, rewards):\n",
    "        sma = np.convolve(rewards, np.ones(50) / 50, mode='valid')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title(\"Training Rewards\", fontsize=14, fontweight='bold')\n",
    "        plt.plot(rewards, label='Raw Reward', color='#F6CE3B', alpha=1)\n",
    "        plt.plot(sma, label='SMA 50', color='#385DAA')\n",
    "        plt.xlabel(\"Step\", fontsize=12, fontweight='bold')\n",
    "        plt.ylabel(\"Rewards\", fontsize=12, fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Save the plot as PDF\n",
    "        filepath = os.path.join(self.save_path, self.filename)\n",
    "        plt.savefig(filepath, format='pdf')\n",
    "\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "    def __init__(\n",
    "        self, \n",
    "        df: pd.DataFrame,\n",
    "        window_size: int, \n",
    "        frame_bound: tuple,\n",
    "        initial_balance: int, \n",
    "        max_shares: int,      \n",
    "        trade_max: int = 100,   \n",
    "        trade_fee_percent: float = 0.001,\n",
    "        risk_free_rate: float = 0.01 / 252\n",
    "    ):\n",
    "        self.window_size = window_size\n",
    "        self.frame_bound = frame_bound\n",
    "        self.initial_balance = initial_balance\n",
    "        self.max_shares = max_shares\n",
    "        self.trade_max = trade_max\n",
    "        self.trade_fee_percent = trade_fee_percent\n",
    "        self.risk_free_rate = risk_free_rate\n",
    "        \n",
    "        self.df = self.add_technical_indicators(df)\n",
    "        \n",
    "        self.prices, self.signal_features = self._process_data()\n",
    "        self.shape = (self.window_size, self.signal_features.shape[1])\n",
    "        super().__init__()\n",
    "\n",
    "        # Define action space - one action per stock\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(len(df.columns.levels[0]),), dtype=np.float64)\n",
    "        \n",
    "        # Define observation space\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=self.shape,\n",
    "            dtype=np.float64\n",
    "        )\n",
    "        \n",
    "        # Episode state variables\n",
    "        self._start_tick = self.window_size\n",
    "        self._end_tick = len(self.prices) - 1\n",
    "        self._truncated = None\n",
    "        self._current_tick = None\n",
    "        self._last_trade_tick = None\n",
    "        self._total_reward = None\n",
    "        self._total_profit = None\n",
    "        self._trade_count = None\n",
    "        self.history = None\n",
    "        \n",
    "        # Trading statistics variables\n",
    "        self._balance = None\n",
    "        self._shares_held = None\n",
    "        self._portfolio_value = None\n",
    "        self._prev_portfolio_value = None\n",
    "        self._last_action = None\n",
    "        self._peak_portfolio_value = None\n",
    "        self._transaction_cost = 0\n",
    "        self._step_transaction_cost = 0 \n",
    "\n",
    "        # Reward tracking variables\n",
    "        self.min_reward = None\n",
    "        self.max_reward = None\n",
    "        self.daily_returns = []\n",
    "        \n",
    "        self.reset()\n",
    "        \n",
    "    def add_technical_indicators(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Add technical indicators to the dataframe\n",
    "        \"\"\"\n",
    "        for stock in df.columns.levels[0]:\n",
    "            # Bollinger Bands\n",
    "            df[(stock, 'BBUpper')], df[(stock, 'BBMiddle')], df[(stock, 'BBLower')] = talib.BBANDS(\n",
    "                df[(stock, 'close')], timeperiod=20, nbdevup=2, nbdevdn=2\n",
    "            )\n",
    "            # MACD\n",
    "            df[(stock, 'MACD')], df[(stock, 'MACDSignal')], df[(stock, 'MACDHist')] = talib.MACD(\n",
    "                df[(stock, 'close')], fastperiod=12, slowperiod=26, signalperiod=9\n",
    "            )\n",
    "            # RSI - Relative Strength Index\n",
    "            df[(stock, 'RSI')] = talib.RSI(df[(stock, 'close')], timeperiod=14)\n",
    "            # CCI - Commodity Channel Index\n",
    "            df[(stock, 'CCI')] = talib.CCI(df[(stock, 'high')], df[(stock, 'low')], df[(stock, 'close')], timeperiod=14)\n",
    "            # ADX - Average Directional Index\n",
    "            df[(stock, 'ADX')] = talib.ADX(df[(stock, 'high')], df[(stock, 'low')], df[(stock, 'close')], timeperiod=14)\n",
    "            # ATR - Average True Range\n",
    "            df[(stock, 'ATR')] = talib.ATR(df[(stock, 'high')], df[(stock, 'low')], df[(stock, 'close')], timeperiod=14)\n",
    "            \n",
    "            # Handle NaN values\n",
    "            df.fillna(0, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed, options=options)\n",
    "        if seed is not None:\n",
    "            self.action_space.seed(int(self.np_random.uniform(0, seed)))\n",
    "\n",
    "        # Reload processed data\n",
    "        self.prices, self.signal_features = self._process_data()\n",
    "        \n",
    "        # Reset episode state variables\n",
    "        self._start_tick = self.window_size\n",
    "        self._end_tick = len(self.prices) - 1\n",
    "        self._truncated = False\n",
    "        self._current_tick = self._start_tick\n",
    "        self._last_trade_tick = self._current_tick - 1\n",
    "        self._total_reward = 0.0\n",
    "        self._total_profit = 0.0\n",
    "        self._trade_count = 0\n",
    "        self.history = {}\n",
    "        \n",
    "        # Reset trading statistics\n",
    "        self.daily_returns = []\n",
    "        self.min_reward = float('inf')\n",
    "        self.max_reward = float('-inf')\n",
    "        self._balance = self.initial_balance\n",
    "        self._shares_held = {stock: 0 for stock in self.df.columns.levels[0]}\n",
    "        self._last_action = np.zeros(len(self.df.columns.levels[0]))\n",
    "        self._transaction_cost = 0\n",
    "        self._step_transaction_cost = 0\n",
    "        \n",
    "        # Initialize portfolio value\n",
    "        self._portfolio_value = self._balance\n",
    "        self._prev_portfolio_value = self._portfolio_value\n",
    "        self._peak_portfolio_value = self._portfolio_value\n",
    "\n",
    "        return self._get_observation(), self._get_info()\n",
    "    \n",
    "    def step(self, action):\n",
    "        self._truncated = False\n",
    "        self._current_tick += 1\n",
    "        self._last_action = action\n",
    "    \n",
    "        if self._current_tick == self._end_tick:\n",
    "            self._truncated = True\n",
    "\n",
    "        # Update portfolio based on action\n",
    "        self._update_profit(action)\n",
    "        \n",
    "        # Calculate reward\n",
    "        step_reward = self._calculate_reward()\n",
    "        self._total_reward += step_reward\n",
    "    \n",
    "        # Update trade tracking\n",
    "        self._last_trade_tick = self._current_tick\n",
    "        \n",
    "        # Get observation and info\n",
    "        observation = self._get_observation()\n",
    "        info = self._get_info()\n",
    "        \n",
    "        # Update history\n",
    "        self._update_history(info)\n",
    "    \n",
    "        return observation, step_reward, False, self._truncated, info\n",
    "    \n",
    "    def _get_info(self):\n",
    "        \"\"\"\n",
    "        Return detailed information about current state\n",
    "        \"\"\"\n",
    "        detailed_info = {\n",
    "            'balance': self._balance,\n",
    "            'shares_held': self._shares_held,\n",
    "            'last_action': self._last_action,\n",
    "            'portfolio_value': self._portfolio_value,\n",
    "            'total_reward': self._total_reward,\n",
    "            'total_profit': self._total_profit,\n",
    "            'overall_transaction_cost': self._transaction_cost,\n",
    "            'average_daily_return': np.mean(self.daily_returns) if self.daily_returns else 0,\n",
    "        }\n",
    "        return detailed_info\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Return observation window of features\n",
    "        \"\"\"\n",
    "        return self.signal_features[max(0, self._current_tick - self.window_size + 1):self._current_tick + 1]\n",
    "    \n",
    "    def _update_history(self, info):\n",
    "        \"\"\"\n",
    "        Update history dictionary with info from current step\n",
    "        \"\"\"\n",
    "        if not self.history:\n",
    "            self.history = {key: [] for key in info.keys()}\n",
    "        for key, value in info.items():\n",
    "            self.history[key].append(value)\n",
    "\n",
    "    def _process_data(self):\n",
    "        \"\"\"\n",
    "        Process raw data into normalized features\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _calculate_reward(self):\n",
    "        \"\"\"\n",
    "        Calculate reward for current step\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        \"\"\"\n",
    "        Update portfolio based on action\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VnStockEnv(TradingEnv):\n",
    "    def _process_data(self):\n",
    "        \"\"\"\n",
    "        Enhanced feature processing with advanced financial indicators\n",
    "        \"\"\"\n",
    "        feature_columns = [\n",
    "            'close', 'RSI', 'MACD', 'MACDSignal', 'MACDHist',\n",
    "            'BBUpper', 'BBLower', 'BBMiddle', 'CCI', 'ADX', 'ATR'\n",
    "        ]\n",
    "        prices = {}\n",
    "        signal_features = pd.DataFrame()\n",
    "\n",
    "        for stock in self.df.columns.levels[0]:\n",
    "            # Get close prices for this stock\n",
    "            prices_close = self.df[(stock, 'close')].to_numpy()\n",
    "            # Extract price range based on frame_bound\n",
    "            prices_range = prices_close[self.frame_bound[0] - self.window_size : self.frame_bound[1]]\n",
    "            prices[stock] = prices_range\n",
    "\n",
    "            # Process existing features\n",
    "            for feature in feature_columns:\n",
    "                if feature in self.df.columns.levels[1]:\n",
    "                    # Extract feature data\n",
    "                    data = self.df[(stock, feature)].iloc[self.frame_bound[0] - self.window_size:self.frame_bound[1]].values\n",
    "\n",
    "                    # Double check values\n",
    "                    data = np.nan_to_num(data)\n",
    "\n",
    "                    signal_features[(stock, feature)] = data\n",
    "        \n",
    "        return prices, signal_features.values\n",
    "\n",
    "    def _calculate_reward(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculate reward using a combination of portfolio return and penalties\n",
    "        \"\"\"\n",
    "        # Base reward is the change in portfolio value minus transaction costs\n",
    "        if self._prev_portfolio_value == 0:\n",
    "            return 0\n",
    "\n",
    "        # Calculate portfolio return\n",
    "        portfolio_return = (self._portfolio_value - self._prev_portfolio_value) / self._prev_portfolio_value\n",
    "\n",
    "        # Calculate drawdown penalty\n",
    "        drawdown = (self._peak_portfolio_value - self._portfolio_value) / self._peak_portfolio_value if self._peak_portfolio_value > 0 else 0\n",
    "        drawdown_penalty = 0.01 * drawdown \n",
    "\n",
    "        # Calculate reward as return minus penalties and transaction costs\n",
    "        reward = portfolio_return - drawdown_penalty - (self._step_transaction_cost / self._prev_portfolio_value) - self.risk_free_rate\n",
    "\n",
    "        # Update min and max rewards for potential normalization\n",
    "        self.min_reward = min(self.min_reward, reward)\n",
    "        self.max_reward = max(self.max_reward, reward)\n",
    "        \n",
    "        normalized_reward = (reward - self.min_reward) / (self.max_reward - self.min_reward) if self.max_reward != self.min_reward else 0\n",
    "\n",
    "        return normalized_reward\n",
    "\n",
    "    def _update_profit(self, action):\n",
    "        \"\"\"\n",
    "        Update portfolio based on action\n",
    "        \"\"\"\n",
    "        # Store previous portfolio value for return calculation\n",
    "        self._prev_portfolio_value = self._portfolio_value\n",
    "        self._step_transaction_cost = 0\n",
    "\n",
    "        # Process each stock based on its corresponding action value\n",
    "        for i, stock in enumerate(self.df.columns.levels[0]):\n",
    "            current_price = self.prices[stock][self._current_tick]\n",
    "\n",
    "            if current_price <= 0:\n",
    "                continue  # Skip invalid prices\n",
    "\n",
    "            # Convert action from range [-1, 1] to actual shares to trade\n",
    "            # Use action to determine direction and strength\n",
    "            action_value = action[i]\n",
    "\n",
    "            # Calculate target position based on action\n",
    "            max_shares_to_trade = min(self.max_shares, self.trade_max)\n",
    "            target_shares = int(action_value * max_shares_to_trade)\n",
    "            shares_to_trade = target_shares - self._shares_held[stock]\n",
    "\n",
    "            # Buy shares\n",
    "            if shares_to_trade > 0:\n",
    "                shares_to_buy = min(shares_to_trade, int(self._balance // current_price))\n",
    "                cost = shares_to_buy * current_price\n",
    "                transaction_fee = cost * self.trade_fee_percent\n",
    "                total_cost = cost + transaction_fee\n",
    "\n",
    "                if self._balance >= total_cost and shares_to_buy > 0:\n",
    "                    self._balance -= total_cost\n",
    "                    self._shares_held[stock] += shares_to_buy\n",
    "                    self._step_transaction_cost += transaction_fee\n",
    "                    self._transaction_cost += transaction_fee\n",
    "                    self._trade_count += 1\n",
    "\n",
    "            # Sell shares\n",
    "            elif shares_to_trade < 0:\n",
    "                shares_to_sell = min(abs(shares_to_trade), self._shares_held[stock])\n",
    "                revenue = shares_to_sell * current_price\n",
    "                transaction_fee = revenue * self.trade_fee_percent\n",
    "\n",
    "                if shares_to_sell > 0:\n",
    "                    self._balance += revenue - transaction_fee\n",
    "                    self._shares_held[stock] -= shares_to_sell\n",
    "                    self._step_transaction_cost += transaction_fee\n",
    "                    self._transaction_cost += transaction_fee\n",
    "                    self._trade_count += 1\n",
    "\n",
    "        # Update portfolio value\n",
    "        self._portfolio_value = self._balance + sum(\n",
    "            self._shares_held[stock] * self.prices[stock][self._current_tick]\n",
    "            for stock in self.df.columns.levels[0]\n",
    "        )\n",
    "\n",
    "        # Update peak portfolio value for drawdown calculation\n",
    "        self._peak_portfolio_value = max(self._peak_portfolio_value, self._portfolio_value)\n",
    "\n",
    "        # Calculate daily return\n",
    "        if self._prev_portfolio_value > 0:\n",
    "            daily_return = (self._portfolio_value - self._prev_portfolio_value) / self._prev_portfolio_value\n",
    "            self.daily_returns.append(daily_return)\n",
    "\n",
    "        # Calculate profit\n",
    "        self._total_profit = self._portfolio_value - self.initial_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter for multiple algorithms\n",
    "WINDOW_SIZE = [5, 10, 15, 25]\n",
    "\n",
    "HYPERPARAMS_PPO = [\n",
    "    {\n",
    "        \"name\": \"PPO\",\n",
    "        \"policy\": \"MlpPolicy\",\n",
    "        \"learning_rate\": 4e-4,\n",
    "        \"n_steps\": 2048,\n",
    "        \"batch_size\": 128,\n",
    "        \"n_epochs\": 20,\n",
    "        \"gamma\": 0.995,\n",
    "        \"clip_range\": 0.2,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"PPO_CNN\",\n",
    "        \"policy\": \"CnnPolicy\",\n",
    "        \"learning_rate\": 4e-4,\n",
    "        \"n_steps\": 2048,\n",
    "        \"batch_size\": 128,\n",
    "        \"n_epochs\": 20,\n",
    "        \"gamma\": 0.995,\n",
    "        \"clip_range\": 0.2,\n",
    "    },\n",
    "]\n",
    "\n",
    "HYPERPARAMS_A2C = [\n",
    "    {\n",
    "        \"name\": \"A2C\",\n",
    "        \"policy\": \"MlpPolicy\",\n",
    "        \"learning_rate\": 4e-4,\n",
    "        \"n_steps\": 5,\n",
    "        \"gamma\": 0.99,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"A2C_CNN\",\n",
    "        \"policy\": \"CnnPolicy\",\n",
    "        \"learning_rate\": 4e-4,\n",
    "        \"n_steps\": 5,\n",
    "        \"gamma\": 0.99,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "    },\n",
    "]\n",
    "\n",
    "HYPERPARAMS_SAC = [\n",
    "    {\n",
    "        \"name\": \"SAC\",\n",
    "        \"policy\": \"MlpPolicy\",\n",
    "        \"learning_rate\": 4e-4,\n",
    "        \"buffer_size\": 1000000,\n",
    "        \"batch_size\": 256,\n",
    "        \"gamma\": 0.99,\n",
    "        \"tau\": 0.005,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SAC_CNN\",\n",
    "        \"policy\": \"CnnPolicy\",\n",
    "        \"learning_rate\": 4e-4,\n",
    "        \"buffer_size\": 1000000,\n",
    "        \"batch_size\": 256,\n",
    "        \"gamma\": 0.99,\n",
    "        \"tau\": 0.005,\n",
    "    }\n",
    "]\n",
    "\n",
    "HYPERPARAMS_RPPO = [\n",
    "    {\n",
    "        \"name\": \"RPPO\",\n",
    "        \"policy\": \"MlpLstmPolicy\",\n",
    "        \"learning_rate\": 4e-4,\n",
    "        \"n_steps\": 2048,\n",
    "        \"batch_size\": 64,\n",
    "        \"n_epochs\": 10,\n",
    "        \"gamma\": 0.99,\n",
    "        \"clip_range\": 0.2,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "    }\n",
    "]\n",
    "\n",
    "HYPERPARAMS_TRPO = [\n",
    "    {\n",
    "        \"name\": \"TRPO\",\n",
    "        \"policy\": \"MlpPolicy\",\n",
    "        \"learning_rate\": 4e-4,\n",
    "        \"n_steps\": 2048,\n",
    "        \"batch_size\": 64,\n",
    "        \"n_epochs\": 10,\n",
    "        \"gamma\": 0.99,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_environment(data, window_size, initial_balance, max_shares, trade_max):\n",
    "    \"\"\"Create and configure trading environment\"\"\"\n",
    "    # Set up environment parameters\n",
    "    frame_bound = (window_size, len(data))\n",
    "\n",
    "    # Create environment\n",
    "    env = VnStockEnv(\n",
    "        df=data,\n",
    "        window_size=window_size,\n",
    "        frame_bound=frame_bound,\n",
    "        initial_balance=initial_balance,\n",
    "        max_shares=max_shares,\n",
    "        trade_max=trade_max\n",
    "    )\n",
    "    \n",
    "    print(\"Testing environment...\")\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    print(f\"Observation shape: {observation.shape}\")\n",
    "        \n",
    "    return env\n",
    "\n",
    "def train_model(model_class, params, data, initial_balance, max_shares, trade_max, window_size, timesteps=500000):\n",
    "    \"\"\"Train a model with specific parameters\"\"\"\n",
    "    # Create environment\n",
    "    env = create_environment(data, window_size, initial_balance, max_shares, trade_max)\n",
    "    \n",
    "    # Setup monitoring\n",
    "    model_name = params.pop(\"name\")\n",
    "    os.makedirs(f\"models/{model_name}/{window_size}\", exist_ok=True)\n",
    "    os.makedirs(f\"logs/{model_name}/{window_size}\", exist_ok=True)\n",
    "    \n",
    "    env = Monitor(env, f\"logs/{model_name}/{window_size}\")\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    \n",
    "    # Create callback\n",
    "    callback = CustomLoggingCallback(\n",
    "        verbose = 1, \n",
    "        log_interval = 20000, \n",
    "        save_path=f\"models/{model_name}/{window_size}\", \n",
    "        filename=f\"{model_name}_{window_size}_training.pdf\"\n",
    "    )\n",
    "    \n",
    "    # Create and train model\n",
    "    model = model_class(**params, env=env, verbose=0, device=device)\n",
    "    model.learn(total_timesteps=timesteps, callback=callback)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = f\"models/{model_name}/{model_name}_{window_size}.zip\"\n",
    "    model.save(model_path)\n",
    "    \n",
    "    params[\"name\"] = model_name\n",
    "    \n",
    "    return model_path\n",
    "\n",
    "def evaluate_model(model_path, model_class, data, initial_balance, max_shares, trade_max, window_size):\n",
    "    \"\"\"Evaluate a trained model on test data\"\"\"\n",
    "    # Create test environment\n",
    "    env = create_environment(data, window_size, initial_balance, max_shares, trade_max)\n",
    "    env = Monitor(env, None)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    \n",
    "    # Load model\n",
    "    model = model_class.load(model_path)\n",
    "    \n",
    "    # Run evaluation episodes\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    truncated = False\n",
    "    \n",
    "    # Track performance metrics\n",
    "    portfolio_values = []\n",
    "    returns = []\n",
    "    actions = []\n",
    "    dates = data.index[window_size:]\n",
    "    \n",
    "    while not (done or truncated):\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        portfolio_values.append(info[0]['portfolio_value'])\n",
    "        \n",
    "        # Calculate daily return\n",
    "        if len(portfolio_values) > 1:\n",
    "            daily_return = (portfolio_values[-1] - portfolio_values[-2]) / portfolio_values[-2]\n",
    "            returns.append(daily_return)\n",
    "        \n",
    "        actions.append(action)\n",
    "    \n",
    "    # Check length\n",
    "    if len(dates) == len(portfolio_values) == len(returns) == len(actions):\n",
    "        # Write each output to a CSV file\n",
    "        df = pd.DataFrame({\n",
    "            'Date': dates,\n",
    "            'Portfolio Value': portfolio_values,\n",
    "            'Daily Returns': returns,\n",
    "            'Actions': actions\n",
    "        })\n",
    "        df.to_csv(f\"models/{model_path.split('/')[-1]}/evaluation_results.csv\", index=False)\n",
    "\n",
    "    print(\"Can't save evaluation results!\")\n",
    "    return portfolio_values, returns, actions, dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(portfolio_values, returns):\n",
    "    \"\"\"Calculate trading performance metrics\"\"\"\n",
    "    # Convert to numpy arrays for calculations\n",
    "    portfolio_values = np.array(portfolio_values)\n",
    "    returns = np.array(returns)\n",
    "    \n",
    "    # Total return\n",
    "    total_return = (portfolio_values[-1] / portfolio_values[0]) - 1\n",
    "    \n",
    "    # Annualized return (assuming 252 trading days per year)\n",
    "    n_days = len(returns)\n",
    "    annualized_return = (1 + total_return) ** (252 / n_days) - 1\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    peak = np.maximum.accumulate(portfolio_values)\n",
    "    drawdown = (portfolio_values - peak) / peak\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Sharpe ratio (assuming risk-free rate of 0.01 annually)\n",
    "    risk_free_daily = 0.01 / 252\n",
    "    excess_returns = returns - risk_free_daily\n",
    "    sharpe_ratio = (np.mean(excess_returns) / np.std(returns)) * np.sqrt(252)\n",
    "    \n",
    "    # Sortino ratio (only considering negative returns)\n",
    "    negative_returns = returns[returns < 0]\n",
    "    sortino_ratio = 0\n",
    "    if len(negative_returns) > 0:\n",
    "        sortino_ratio = (np.mean(excess_returns) / np.std(negative_returns)) * np.sqrt(252)\n",
    "    \n",
    "    # Calmar ratio (annualized return divided by max drawdown)\n",
    "    calmar_ratio = 0\n",
    "    if max_drawdown != 0:\n",
    "        calmar_ratio = annualized_return / abs(max_drawdown)\n",
    "    \n",
    "    # Win rate\n",
    "    win_rate = np.sum(returns > 0) / len(returns)\n",
    "    \n",
    "    return {\n",
    "        \"total_return\": total_return,\n",
    "        \"annualized_return\": annualized_return,\n",
    "        \"max_drawdown\": max_drawdown,\n",
    "        \"sharpe_ratio\": sharpe_ratio,\n",
    "        \"sortino_ratio\": sortino_ratio,\n",
    "        \"calmar_ratio\": calmar_ratio,\n",
    "        \"win_rate\": win_rate\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate / Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stocks using: 31\n",
      "Loading TEST data...\n",
      "Fetching 14 Vietnamese stock data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 17 Global stock data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock          AAPL                               ACB                       \\\n",
      "Metric        close     high      low     open  close   high    low   open   \n",
      "2024-01-01  4705.57  4776.54  4661.21  4743.84  20.54  20.79  20.12  20.12   \n",
      "2024-01-02  4705.57  4776.54  4661.21  4743.84  20.54  20.79  20.12  20.12   \n",
      "2024-01-03  4670.33  4711.65  4649.55  4669.57  21.00  21.00  20.37  20.58   \n",
      "2024-01-04  4611.02  4640.93  4584.91  4617.10  21.25  21.55  21.08  21.17   \n",
      "2024-01-05  4592.52  4632.57  4566.92  4613.05  21.38  21.38  21.04  21.25   \n",
      "\n",
      "Stock          AMZN           ...   VIC           VNM                       \\\n",
      "Metric        close     high  ...   low   open  close   high    low   open   \n",
      "2024-01-01  3823.21  3885.69  ...  44.0  44.95  64.65  64.84  64.27  64.56   \n",
      "2024-01-02  3823.21  3885.69  ...  44.0  44.95  64.65  64.84  64.27  64.56   \n",
      "2024-01-03  3785.99  3851.78  ...  43.5  43.50  65.31  65.31  64.37  64.75   \n",
      "2024-01-04  3686.54  3758.19  ...  43.8  44.15  65.31  65.79  65.31  65.41   \n",
      "2024-01-05  3703.62  3738.04  ...  43.9  44.15  65.13  65.60  64.84  65.60   \n",
      "\n",
      "Stock           WMT                             \n",
      "Metric        close     high      low     open  \n",
      "2024-01-01  1334.26  1336.36  1316.67  1317.18  \n",
      "2024-01-02  1334.26  1336.36  1316.67  1317.18  \n",
      "2024-01-03  1334.35  1342.72  1331.25  1338.28  \n",
      "2024-01-04  1321.45  1336.36  1319.19  1333.59  \n",
      "2024-01-05  1312.65  1324.30  1303.36  1322.79  \n",
      "\n",
      "[5 rows x 124 columns]\n",
      "Data loaded successfully.\n",
      "\n",
      "Training PPO models...\n",
      "  Training PPO...\n",
      "Testing environment...\n",
      "Observation shape: (5, 341)\n",
      "Can't save evaluation results!\n",
      "  PPO metrics:\n",
      "    total_return: 0.0103\n",
      "    annualized_return: 0.1135\n",
      "    max_drawdown: -0.0277\n",
      "    sharpe_ratio: 0.9624\n",
      "    sortino_ratio: 1.3289\n",
      "    calmar_ratio: 4.0943\n",
      "    win_rate: 0.6250\n",
      "  Training PPO...\n",
      "Testing environment...\n",
      "Observation shape: (10, 341)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error: Unexpected observation shape (1, 10, 341) for Box environment, please use (5, 341) or (n_env, 5, 341) for the observation shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m                     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 83\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 66\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m params_copy \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# model_path, window_size = train_model(\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#     model_class=model_class,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Evaluate model\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m portfolio_values, returns, actions, dates \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mnguye\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDownloads\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPaper Trading\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTrading-Agent\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPPO\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPPO_5.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPPO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_balance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_shares\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrade_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwin_size\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Calculate performance metrics\u001b[39;00m\n\u001b[0;32m     77\u001b[0m metrics \u001b[38;5;241m=\u001b[39m calculate_metrics(portfolio_values, returns)\n",
      "Cell \u001b[1;32mIn[7], line 78\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model_path, model_class, data, initial_balance, max_shares, trade_max, window_size)\u001b[0m\n\u001b[0;32m     75\u001b[0m dates \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mindex[window_size:]\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (done \u001b[38;5;129;01mor\u001b[39;00m truncated):\n\u001b[1;32m---> 78\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m     81\u001b[0m     portfolio_values\u001b[38;5;241m.\u001b[39mappend(info[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportfolio_value\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\ai\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:557\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    543\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, Optional[\u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[0;32m    544\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\ai\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:365\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(observation) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have passed a tuple to the predict() function instead of a Numpy array or a Dict. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m     )\n\u001b[1;32m--> 365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(obs_tensor, deterministic\u001b[38;5;241m=\u001b[39mdeterministic)\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\ai\\Lib\\site-packages\\stable_baselines3\\common\\policies.py:272\u001b[0m, in \u001b[0;36mBaseModel.obs_to_tensor\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    268\u001b[0m     observation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(observation)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# Dict obs need to be handled separately\u001b[39;00m\n\u001b[1;32m--> 272\u001b[0m     vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[43mis_vectorized_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# Add batch dimension if needed\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     observation \u001b[38;5;241m=\u001b[39m observation\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\ai\\Lib\\site-packages\\stable_baselines3\\common\\utils.py:404\u001b[0m, in \u001b[0;36mis_vectorized_observation\u001b[1;34m(observation, observation_space)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m space_type, is_vec_obs_func \u001b[38;5;129;01min\u001b[39;00m is_vec_obs_func_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation_space, space_type):\n\u001b[1;32m--> 404\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mis_vec_obs_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# for-else happens if no break is called\u001b[39;00m\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Cannot determine if the observation is vectorized with the space type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nguye\\anaconda3\\envs\\ai\\Lib\\site-packages\\stable_baselines3\\common\\utils.py:271\u001b[0m, in \u001b[0;36mis_vectorized_box_observation\u001b[1;34m(observation, observation_space)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Unexpected observation shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBox environment, please use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor (n_env, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) for the observation shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, observation_space\u001b[38;5;241m.\u001b[39mshape)))\n\u001b[0;32m    275\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Error: Unexpected observation shape (1, 10, 341) for Box environment, please use (5, 341) or (n_env, 5, 341) for the observation shape."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    STOCK_LIST_VN = ['FPT', 'VCB', 'VIC', 'GAS', 'VHM', 'BID', 'MBB', 'HVN', 'HPG', 'GVR', 'VNM', 'SSI', 'GEX', 'ACB']\n",
    "    STOCK_LIST_GLOBAL = ['AXP', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HON', 'IBM', 'INTC', 'JPM', 'MSFT', 'NKE', 'GOOGL', 'AMZN', 'WMT', 'NVDA']\n",
    "    print(f\"Number of stocks using: {len(STOCK_LIST_VN) + len(STOCK_LIST_GLOBAL)}\")\n",
    "    \n",
    "    print(\"Loading TRAIN data...\")\n",
    "    START_DATE = '2020-01-01'\n",
    "    END_DATE = '2024-01-01'\n",
    "    train_data = fetch_stock_data(STOCK_LIST_VN, STOCK_LIST_GLOBAL, START_DATE, END_DATE)\n",
    "    \n",
    "    # Check data date from start to end to ensure it is run frequently\n",
    "    \n",
    "    # print(train_data.head())\n",
    "    \n",
    "    print(\"Loading TEST data...\")\n",
    "    START_DATE = '2024-01-01'\n",
    "    END_DATE = '2025-04-13'\n",
    "    test_data = fetch_stock_data(STOCK_LIST_VN, STOCK_LIST_GLOBAL, START_DATE, END_DATE)\n",
    "    \n",
    "    # print(test_data.head())\n",
    "    print(\"Data loaded successfully.\")\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    \n",
    "    # Dictionary to store results for all models\n",
    "    all_results = {}\n",
    "    \n",
    "    # Define model classes and their hyperparameter lists\n",
    "    models_to_train = [\n",
    "        (PPO, HYPERPARAMS_PPO),\n",
    "        (A2C, HYPERPARAMS_A2C),\n",
    "        (SAC, HYPERPARAMS_SAC),\n",
    "        (RecurrentPPO, HYPERPARAMS_RPPO),\n",
    "        (TRPO, HYPERPARAMS_TRPO)\n",
    "    ]\n",
    "    \n",
    "    # Train all models with different hyperparameters\n",
    "    for model_class, hyperparams_list in models_to_train:\n",
    "        model_type = model_class.__name__\n",
    "        print(f\"\\nTraining {model_type} models...\")\n",
    "        \n",
    "        for params in hyperparams_list:\n",
    "            for win_size in WINDOW_SIZE:\n",
    "                model_name = params[\"name\"]\n",
    "                print(f\"  Training {model_name}...\")\n",
    "\n",
    "                # Create a copy of params to avoid modifying the original\n",
    "                params_copy = params.copy()\n",
    "\n",
    "                # Train model\n",
    "                model_path, window_size = train_model(\n",
    "                    model_class=model_class,\n",
    "                    params=params_copy,\n",
    "                    data=train_data,\n",
    "                    initial_balance=10000,\n",
    "                    max_shares=500,\n",
    "                    trade_max=100,\n",
    "                    timesteps=200000,\n",
    "                    window_size=win_size\n",
    "                )\n",
    "\n",
    "                # Evaluate model\n",
    "                portfolio_values, returns, actions, dates = evaluate_model(\n",
    "                    model_path=model_path,\n",
    "                    model_class=model_class,\n",
    "                    data=test_data,\n",
    "                    initial_balance=10000,\n",
    "                    max_shares=500,\n",
    "                    trade_max=100,\n",
    "                    window_size=win_size\n",
    "                )\n",
    "\n",
    "                # Calculate performance metrics\n",
    "                metrics = calculate_metrics(portfolio_values, returns)\n",
    "                print(f\"  {model_name} metrics:\")\n",
    "                for key, value in metrics.items():\n",
    "                    print(f\"    {key}: {value:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
